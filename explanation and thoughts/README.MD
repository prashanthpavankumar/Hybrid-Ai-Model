# ðŸ¤– Hybrid AI System: Thinker + Doer Architecture

This project is a **hybrid AI system** built from scratch. It consists of two collaborating models **"The idea is to make two models precisely Generative LLM and an AI Agent in ONE FRAMEWORK"**:

- **Model A (Thinker)**: A generative model like GPT that understands, reasons, and suggests tasks.
- **Model B (Doer)**: An agent-based system that can act in the real world â€” booking tickets, opening URLs, fetching data via APIs, etc.

Together, they simulate intelligent decision-making followed by real-world action â€” creating a powerful and practical AI assistant.

---

## ðŸ“Œ Objectives

- Combine LLM (generative AI) with agent-based automation
- Enable an AI assistant to **think** and then **act**
- Learn full-stack AI engineering, tools, and architecture hands-on

---

## ðŸ› ï¸ Tools & Technologies

| Layer | Tool / Framework | Description |
|-------|------------------|-------------|
| ðŸ§  Model A (Thinker) | OpenAI GPT / Ollama / LLaMA | Natural language reasoning and generation |
| ðŸ¦¾ Model B (Doer) | LangChain Agents / Selenium / Requests | Executes tasks via browser or API |
| ðŸ§ª Workflow Control | Python, Logic Trees | Controls communication between A and B |
| ðŸ–¥ï¸ UI Layer | Gradio / Streamlit / CLI | Interface to interact with both models |
| ðŸŒ Web API | Flask / FastAPI | Handles backend routing if deployed |
| ðŸ“¦ Deployment (Mandatory) | Hugging Face Spaces / Render / Localhost(it was never an option) | For hosting the hybrid system |

---

## ðŸ“ Architecture Overview
+-------------+ +--------------------+ +----------------+
| User | ---> | Model A (Thinker) | ---> | Decision JSON |
+-------------+ +--------------------+ +--------+-------+
|
v
+-------------+-------------+
| Model B (Doer Agent) |
+-------------+-------------+
|
v
[ Executes task via API /  browser / OS automation ]
## Example real life case

---

## ðŸ§© Workflow

1. **User Input** â€” e.g., "I want to travel to Bangalore"
2. **Model A processes** intent, generates structured output like:
   ```json
   {
     "intent": "travel_booking",
     "destination": "Bangalore",
     "type": "train",
     "date": "next Monday"
   }
 3.  **Model B executes the task via tools like:**

     Google Maps API

    IRCTC or MakeMyTrip API (or Selenium simulation)

    Fetches results or executes bookings

4. **Response displayed** via UI or CLI
**ðŸ“š What we're gonna Learn**
Prompt engineering & context planning

Real-world LLM integration (OpenAI / Ollama)

Automation with LangChain agents or Selenium

API calling & data parsing

UI building (Gradio / Streamlit)

Hybrid AI design patterns
#Here's the complete overview of the plan in Phases,
**ðŸ“† Project Milestones**
**Phase	          Goal	                              Status**
**Phase 1	      Learn Python, Flask, APIs	          ðŸ”„ In Progress**
**Phase 2	      Build Thinker (Model A)	            â¬œ Not Started**
**Phase 3	      Build Doer (Model B)	              â¬œ Not Started**
**Phase 4	      Connect A â†” B	                      â¬œ Not Started**
**Phase 5	      Add UI	                            â¬œ Not Started**
**Phase 6	      Final Testing	                      â¬œ Not Started**
**Phase 7	      Deployment	                        â¬œ Not Started**




